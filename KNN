import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix
from sklearn.utils import resample

# Load the dataset
data = pd.read_csv("car.data", sep=",")

# Define the columns in the dataset
columns = ["buying", "maint", "doors", "persons", "lug_boot", "safety"]

# Select relevant columns
data = data[columns]

# Encode categorical variables
label_encoders = {}
for column in data.columns:
    le = LabelEncoder() # Create LabelEncoder for each column
    data[column] = le.fit_transform(data[column]) # Transform into numerical data
    label_encoders[column] = le # Store

# Separate classes
low_data = data[data['buying'] == label_encoders['buying'].transform(['low'])[0]]
med_data = data[data['buying'] == label_encoders['buying'].transform(['med'])[0]]
high_data = data[data['buying'] == label_encoders['buying'].transform(['high'])[0]]
vhigh_data = data[data['buying'] == label_encoders['buying'].transform(['vhigh'])[0]]

# Combine the datasets
balanced_data = pd.concat([low_data, med_data, high_data, vhigh_data])

# Split the dataset into features X and the target y
X = balanced_data.drop(["buying"], axis=1)  # All other features
y = balanced_data["buying"]  # Price category


# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)

# Attribute scaling
sc_x = StandardScaler()
X_train = sc_x.fit_transform(X_train)
X_test = sc_x.transform(X_test)

# Testing the best K values using cross-validation
best_k = 1
best_score = 0
for k in range(1, 50):
    knn = KNeighborsClassifier(n_neighbors=k)
    cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')
    avg_score = cv_scores.mean()
    if avg_score > best_score:
        best_score = avg_score
        best_k = k

print(f"Best K: {best_k} with cross-validated accuracy: {best_score}")

# Initialize the best KNN classifier
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)

# Predict the test set results
y_pred = knn.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion Matrix')
print(cm)

# Evaluate the model
f1 = f1_score(y_test, y_pred, average='weighted')
accuracy = accuracy_score(y_test, y_pred)

print(f"F1 Score: {f1}")
print(f"Test Accuracy: {accuracy}")
